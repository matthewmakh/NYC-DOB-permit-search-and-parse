# ğŸš€ NYC DOB Permit Scraper - Complete Guide

**Last Updated:** November 15, 2025  
**Repository:** https://github.com/matthewmakh/NYC-DOB-permit-search-and-parse  
**Dashboard:** https://leads.installersny.com

---

## ğŸ“‹ Table of Contents

1. [System Overview](#system-overview)
2. [Data Pipeline Flow](#data-pipeline-flow)
3. [Local Development](#local-development)
4. [Railway Deployment](#railway-deployment)
5. [Data Quality & Monitoring](#data-quality--monitoring)
6. [Troubleshooting](#troubleshooting)

---

## ğŸ¯ System Overview

### What This System Does

Scrapes NYC DOB permit data, enriches it with property intelligence, and displays it in an interactive dashboard.

### Key Features

- âœ… **Permit Scraping**: Gets permit data from NYC DOB BIS website
- âœ… **Contact Extraction**: Extracts contacts, phone numbers, emails, Block & Lot
- âœ… **BBL Generation**: Derives 10-digit BBL from Block + Lot + Borough
- âœ… **Dual Owner Data**: Corporate owner (PLUTO) + Current taxpayer (RPAD)
- âœ… **Property Intelligence**: Assessed values, building characteristics, renovations
- âœ… **Transaction History**: Sale dates, prices, mortgages (ACRIS)
- âœ… **Geocoding**: Latitude/longitude for mapping
- âœ… **Interactive Dashboard**: Two views (Permit & Building) with filters

### Technology Stack

- **Backend**: Python, Flask, Selenium (for scraping)
- **Database**: PostgreSQL (Railway)
- **Frontend**: HTML, JavaScript, CSS
- **Deployment**: Railway (dashboard + cron jobs)
- **Data Sources**: NYC DOB BIS, PLUTO, RPAD, ACRIS, Geoclient API

---

## ğŸ”„ Data Pipeline Flow

### Complete Automation Pipeline

```
1. permit_scraper.py
   â””â”€ Scrapes DOB BIS for basic permit info
   â””â”€ Saves: permit_no, address, owner, filing_rep, work_type

2. add_permit_contacts.py
   â””â”€ Clicks into EACH permit detail page
   â””â”€ Extracts: contacts, phones, emails, block, lot, BIN

3. run_enrichment_pipeline.py (Master Pipeline)
   â”‚
   â”œâ”€ Step 1: step1_link_permits_to_buildings.py
   â”‚  â””â”€ Derives full 10-digit BBL: Borough(1)+Block(5)+Lot(4)
   â”‚  â””â”€ Creates building records
   â”‚  â””â”€ Links permits to buildings
   â”‚
   â”œâ”€ Step 2: step2_enrich_from_pluto.py
   â”‚  â””â”€ PLUTO: Corporate owner, building details, year altered
   â”‚  â””â”€ RPAD: Current taxpayer, assessed values
   â”‚
   â”œâ”€ Step 3: step3_enrich_from_acris.py
   â”‚  â””â”€ ACRIS: Sale dates, prices, mortgages
   â”‚
   â””â”€ Step 4: geocode_permits.py
      â””â”€ NYC Geoclient API: Latitude/longitude

4. Dashboard (leads.installersny.com)
   â””â”€ Displays enriched data in two views
```

### Important: BBL Generation

**BBL is NOT from an external API** - we derive it locally:
- Block & Lot come from `add_permit_contacts.py` (scraped from permit detail pages)
- Borough comes from permit number (first digit: 1=Manhattan, 2=Bronx, 3=Brooklyn, 4=Queens, 5=Staten Island)
- Combined into 10-digit BBL: `3050080064` = Borough 3, Block 05008, Lot 0064

---

## ğŸ’» Local Development

### Initial Setup

```bash
# Clone repository
git clone https://github.com/matthewmakh/NYC-DOB-permit-search-and-parse.git
cd NYC-DOB-permit-search-and-parse

# Create virtual environment
python3 -m venv venv-permit
source venv-permit/bin/activate

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Edit .env with your database credentials
```

### Environment Variables (.env)

```bash
# Database (Railway PostgreSQL)
DB_HOST=maglev.proxy.rlwy.net
DB_PORT=26571
DB_USER=postgres
DB_PASSWORD=your_password
DB_NAME=railway

# NYC Geoclient API (free - get at developer.cityofnewyork.us)
NYC_GEOCLIENT_APP_ID=your_app_id
NYC_GEOCLIENT_APP_KEY=your_app_key

# Optional Performance Tuning
BUILDING_BATCH_SIZE=500  # Buildings per enrichment run
API_DELAY=0.1            # Seconds between API calls
GEOCODE_BATCH_SIZE=10    # Permits per geocoding run
```

### Running Scripts Locally

```bash
# Activate environment
source venv-permit/bin/activate

# Run permit scraper
python permit_scraper.py

# Extract contacts (after scraper)
python add_permit_contacts.py

# Run full enrichment pipeline
python run_enrichment_pipeline.py

# Run dashboard locally
cd dashboard_html
python app.py
# Visit: http://localhost:5001
```

### Testing Individual Steps

```bash
# Test just BBL generation
python step1_link_permits_to_buildings.py

# Test just PLUTO+RPAD enrichment
BUILDING_BATCH_SIZE=10 python step2_enrich_from_pluto.py

# Test just ACRIS
python step3_enrich_from_acris.py

# Test just geocoding
python geocode_permits.py
```

---

## ğŸš‚ Railway Deployment

### Current Railway Services

| Service | Type | Config File | Schedule | Purpose |
|---------|------|-------------|----------|---------|
| **NYC-DOB-permit-search-and-parse** | Web App | `dashboard_html/railway.json` | Always On | Dashboard (leads.installersny.com) |
| **Postgres** | Database | - | Always On | PostgreSQL database |
| **Building-Enrichment-Pipeline** | Cron | `railway.enrichment.json` | Daily 3 AM | Master pipeline (all 4 steps) |

### Setup New Enrichment Pipeline Service

#### Option A: Replace Existing Geocode Service (Recommended)

1. Go to Railway â†’ `Geocode-Properties-CRON` service
2. **Settings** â†’ **Config File Path**
3. Change from `railway.geocode.json` to `railway.enrichment.json`
4. Done! Service now runs full pipeline instead of just geocoding

#### Option B: Create New Service

1. Railway â†’ Your Project â†’ **"+ Create"**
2. Select **"GitHub Repo"** â†’ `NYC-DOB-permit-search-and-parse`
3. Click on service â†’ **Settings**
4. **Service Name**: `Building-Enrichment-Pipeline`
5. **Config File Path**: `railway.enrichment.json`
6. **Variables**: Add reference to `Postgres.DATABASE_URL`
7. **Cron Schedule**: `0 3 * * *` (daily at 3 AM UTC)

### Environment Variables (Railway)

Railway automatically provides:
- `DATABASE_URL` (from PostgreSQL service)

Optional performance tuning:
- `BUILDING_BATCH_SIZE=500`
- `API_DELAY=0.1`
- `NYC_GEOCLIENT_APP_ID` (for geocoding)
- `NYC_GEOCLIENT_APP_KEY` (for geocoding)

### Monitoring Deployments

1. Go to service â†’ **Deployments** tab
2. Click on deployment â†’ **View Logs**
3. Look for:
```
âœ… PIPELINE COMPLETED SUCCESSFULLY
   Step 1: âœ… SUCCESS
   Step 2: âœ… SUCCESS
   Step 3: âœ… SUCCESS
   Step 4: âœ… SUCCESS
```

### Manual Test Run

1. **Deployments** tab
2. Click **â‹®** (three dots) â†’ **"Restart"**
3. **View Logs** to watch execution

---

## ğŸ“Š Data Quality & Monitoring

### Expected Success Rates

| Data Source | Expected | Why Not 100%? |
|-------------|----------|---------------|
| **BBL Generation** | 100% | Derived locally from block+lot |
| **PLUTO** | 90-95% | New construction, data lag |
| **RPAD** | 60-75% | Not all properties taxed (govt, religious) |
| **ACRIS** | 30-50% | Many buildings never sold publicly |
| **Geocoding** | 95-100% | Address format variations |

### Automatic Retry Logic

**All steps automatically retry failed records on next run:**

```sql
-- Step 1: Retries permits without BBL
WHERE block IS NOT NULL AND lot IS NOT NULL AND bbl IS NULL

-- Step 2: Retries buildings missing owner data
WHERE (current_owner_name IS NULL OR owner_name_rpad IS NULL)

-- Step 3: Retries buildings without transaction data
WHERE purchase_date IS NULL

-- Step 4: Retries permits without coordinates
WHERE latitude IS NULL
```

**This means:** Every failed enrichment automatically retries on the next scheduled run. The system is self-healing!

### Check Data Status

```bash
source venv-permit/bin/activate
python -c "
import psycopg2, os
from dotenv import load_dotenv
load_dotenv()

conn = psycopg2.connect(f'postgresql://{os.getenv(\"DB_USER\")}:{os.getenv(\"DB_PASSWORD\")}@{os.getenv(\"DB_HOST\")}:{os.getenv(\"DB_PORT\")}/{os.getenv(\"DB_NAME\")}')
cur = conn.cursor()

print('ğŸ“Š Enrichment Status:')
cur.execute('SELECT COUNT(*) FROM buildings')
print(f'Total buildings: {cur.fetchone()[0]}')

cur.execute('SELECT COUNT(*) FROM buildings WHERE current_owner_name IS NOT NULL')
print(f'With PLUTO data: {cur.fetchone()[0]}')

cur.execute('SELECT COUNT(*) FROM buildings WHERE owner_name_rpad IS NOT NULL')
print(f'With RPAD data: {cur.fetchone()[0]}')

cur.execute('SELECT COUNT(*) FROM buildings WHERE purchase_date IS NOT NULL')
print(f'With ACRIS data: {cur.fetchone()[0]}')

cur.execute('SELECT COUNT(*) FROM permits WHERE latitude IS NOT NULL')
geocoded = cur.fetchone()[0]
cur.execute('SELECT COUNT(*) FROM permits')
total = cur.fetchone()[0]
print(f'Geocoded: {geocoded}/{total} ({100*geocoded/total:.1f}%)')

conn.close()
"
```

### Pipeline Execution Time

- **Small dataset (100 buildings):** ~1 minute
- **Medium dataset (500 buildings):** ~5 minutes
- **Large dataset (1000+ buildings):** ~10-15 minutes

Each step processes in batches and respects API rate limits.

---

## ğŸ› Troubleshooting

### Common Issues

#### "BBL is NULL for many permits"
**Cause:** Need to run `add_permit_contacts.py` first to get block/lot  
**Fix:** Ensure contact extraction runs before enrichment pipeline

#### "RPAD returns no data"
**Cause:** Not all buildings are in RPAD (normal)  
**Fix:** Expected - 60-75% success is normal. System will retry automatically.

#### "ACRIS returns 400 errors"
**Cause:** Was a bug (fixed in latest version)  
**Fix:** Pull latest code from GitHub, uses borough/block/lot fields now

#### "Pipeline takes too long"
**Cause:** Rate limiting delays  
**Fix:** Normal behavior. API_DELAY=0.1 prevents rate limit errors.

#### "Geocoding slow progress"
**Cause:** Batch size set to 10 permits per run  
**Fix:** Increase `GEOCODE_BATCH_SIZE` or let it run daily to gradually complete

#### "Dashboard not showing new data"
**Cause:** Dashboard caches data or hasn't redeployed  
**Fix:** Railway auto-deploys from GitHub. Check deployment logs.

### Railway Issues

#### Service won't start
- Verify `railway.enrichment.json` exists in repo root
- Check config file path spelling in Railway settings
- Ensure DATABASE_URL is connected

#### Module not found errors
- Check `requirements.txt` includes all dependencies
- Railway auto-installs from requirements.txt
- Try manual redeploy

#### Cron not running
- Verify schedule syntax: `0 3 * * *`
- Check service isn't paused
- Look for "Next run" countdown in Deployments

### Database Issues

#### Connection errors
- Verify DATABASE_URL in Railway variables
- Check PostgreSQL service is running
- Test connection locally with credentials

#### Missing columns
- Run migration scripts in order:
  - `migrate_add_buildings.py`
  - `migrate_add_dual_owner_fields.py`
  - `migrate_add_building_intelligence.py`

---

## ğŸ“š Database Schema Reference

### permits table (main fields)
```sql
id, permit_no, address, owner, filing_rep, work_type,
block, lot, bbl,  -- Added by add_permit_contacts + step1
contacts, phone_numbers, email,  -- Added by add_permit_contacts
latitude, longitude,  -- Added by geocode_permits
use, stories, total_units, filing_date, status
```

### buildings table (main fields)
```sql
id, bbl, address, block, lot, bin,
current_owner_name,        -- Corporate owner (PLUTO)
owner_name_rpad,           -- Current taxpayer (RPAD)
assessed_land_value,       -- RPAD or PLUTO
assessed_total_value,      -- RPAD or PLUTO
year_built, year_altered,  -- PLUTO
building_class, land_use,  -- PLUTO
residential_units, total_units, num_floors,  -- PLUTO
building_sqft, lot_sqft,   -- PLUTO
purchase_date, purchase_price, mortgage_amount  -- ACRIS
```

---

## ğŸ¯ Quick Reference

### Cron Schedules
- `0 3 * * *` - Daily at 3 AM
- `0 */6 * * *` - Every 6 hours
- `0 3 * * 0` - Weekly (Sunday 3 AM)
- `*/30 * * * *` - Every 30 minutes

### API Endpoints
- PLUTO: `https://data.cityofnewyork.us/resource/64uk-42ks.json`
- RPAD: `https://data.cityofnewyork.us/resource/yjxr-fw8i.json`
- ACRIS: `https://data.cityofnewyork.us/resource/8h5j-fqxa.json`
- Geoclient: `https://api.nyc.gov/geo/geoclient/v2`

### Free API Keys Needed
- NYC Geoclient: https://developer.cityofnewyork.us/ (free)
- PLUTO/RPAD/ACRIS: No key needed (NYC Open Data)

### File Structure
```
/
â”œâ”€â”€ run_enrichment_pipeline.py        # Master orchestrator
â”œâ”€â”€ step1_link_permits_to_buildings.py
â”œâ”€â”€ step2_enrich_from_pluto.py
â”œâ”€â”€ step3_enrich_from_acris.py
â”œâ”€â”€ geocode_permits.py
â”œâ”€â”€ permit_scraper.py
â”œâ”€â”€ add_permit_contacts.py
â”œâ”€â”€ railway.enrichment.json           # Cron config
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                               # Local credentials
â””â”€â”€ dashboard_html/
    â”œâ”€â”€ app.py                         # Flask backend
    â”œâ”€â”€ templates/
    â”‚   â”œâ”€â”€ index.html
    â”‚   â””â”€â”€ permit_detail.html
    â””â”€â”€ static/
        â”œâ”€â”€ js/app.js
        â””â”€â”€ css/styles.css
```

---

## ğŸ‰ Success Checklist

Your system is working correctly if:

- [ ] Permits have block, lot, and BBL
- [ ] Buildings show both owner names (PLUTO + RPAD)
- [ ] Assessed values display in dashboard
- [ ] Recent renovations show ğŸ”¥ badge (year_altered â‰¤ 5 years)
- [ ] Some buildings have ACRIS transaction data (~30-50%)
- [ ] Geocoding achieves ~100% success over time
- [ ] Pipeline completes in ~5 minutes
- [ ] Dashboard loads at leads.installersny.com
- [ ] Both views work (Permit View + Building View)
- [ ] Filters and search function properly

---

**Questions or Issues?**  
Check Railway logs first, then review troubleshooting section above.

**Repository:** https://github.com/matthewmakh/NYC-DOB-permit-search-and-parse  
**Latest Commit:** d09181e (Master enrichment pipeline + ACRIS fix)
